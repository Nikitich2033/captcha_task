{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Recognized digits: 848288\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist_model = load_model(\"mnist_model.h5\")\n",
    "\n",
    "def segment_img(input_img):\n",
    "    # Convert the PIL Image to a NumPy array\n",
    "    image_array = np.array(input_img)\n",
    "    \n",
    "    # Image processing\n",
    "    # Convert to grayscale\n",
    "    img = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Adaptive thresholding\n",
    "    th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 17, 2)\n",
    "\n",
    "    # Otsu thresholding\n",
    "    ret2, th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Otsu thresholding with Gaussian blur\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    ret3, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "    dilation = cv2.dilate(th3, kernel, iterations=1)\n",
    "\n",
    "    erosion = cv2.erode(dilation, kernel, iterations=1)\n",
    "\n",
    "    kernel = np.ones((3,1), np.uint8)\n",
    "    dilation = cv2.dilate(erosion, kernel, iterations=1)\n",
    "\n",
    "    # Get individual letters\n",
    "    x, y, w, h = 22, 10, 20, 38\n",
    "    segments = []\n",
    "    for i in range(6):\n",
    "        # Save each character as a separate image\n",
    "        digit = dilation[y:y + h, x:x + w]\n",
    "\n",
    "        # Add a white border of 5 pixels\n",
    "        digit = cv2.copyMakeBorder(digit, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "\n",
    "        # Convert the digit to PIL Image\n",
    "        digit_pil = Image.fromarray(digit)\n",
    "\n",
    "        # Append the digit to the list of segments\n",
    "        segments.append(digit_pil)\n",
    "\n",
    "        x += w\n",
    "\n",
    "    return segments\n",
    "\n",
    "# Load the image file\n",
    "image_file = \"captcha_imgs/captcha_0.jpg\"\n",
    "with open(image_file, 'rb') as file:\n",
    "    image_data = base64.b64encode(file.read()).decode('utf-8')\n",
    "\n",
    "# Prepare the request payload\n",
    "payload = {'image': image_data}\n",
    "\n",
    "# Decode image from base64 and create an Image object\n",
    "image_bytes = base64.b64decode(image_data)\n",
    "image = Image.open(BytesIO(image_bytes))\n",
    "\n",
    "# Segment the image\n",
    "segmented_images = segment_img(image)\n",
    "\n",
    "# Display all segments using Matplotlib\n",
    "fig, axs = plt.subplots(1, len(segmented_images), figsize=(10, 4))\n",
    "for i, segment in enumerate(segmented_images):\n",
    "    axs[i].imshow(segment, cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predict the digits\n",
    "recognized_text = \"\"\n",
    "for segment in segmented_images:\n",
    "    # Preprocess the segment\n",
    "    segment = np.array(segment)\n",
    "    segment = cv2.resize(segment, (28, 28))\n",
    "    segment = np.invert(np.array([segment]))\n",
    "    \n",
    "    # Predict the digit using the pre-trained Keras MNIST model\n",
    "    digit = mnist_model.predict(segment)\n",
    "    \n",
    "    # Append the recognized digit to the recognized text\n",
    "    recognized_text += str(np.argmax(digit))\n",
    "\n",
    "print(\"Recognized digits:\", recognized_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
